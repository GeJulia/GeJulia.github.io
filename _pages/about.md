---
permalink: /
title: ""
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am a Ph.D. student with a keen interest in the dynamic and ever-evolving field of Computer Vision. 
Under the supervision of [Prof. Dr. Ing. Margret Keuper](https://www.uni-mannheim.de/dws/people/professors/prof-dr-ing-margret-keuper/) at the University of Mannheim in cooperation with [Prof. Dr. Janis Keuper](https://imla.hs-offenburg.de/janis-keuper/) at IMLA, Offenburg, I am able to explore this exciting field at the highest level. 

My research focuses on signal processing fundamentals, which I apply in modern deep learning approaches to create innovative solutions that push the boundaries of what's possible. Especially, my current focus lies at the intersection of signal processing fundamentals and convolutional neural networks (CNNs). Through extensive analysis of various components within CNNs, I aim to leverage my signal processing expertise to address current limitations and optimize their performance. Adversarial attacks, in particular, provide a valuable means to assess these vulnerabilities of CNNs and refine their robustness for real-world tasks. As such, I am equally intrigued by adversarial attacks and defences.

News
======
**05/2024**
Our paper [As large as it gets – Studying Infinitely Large Convolutions via Neural Implicit Frequency Filters](https://openreview.net/forum?id=xRy1YRcHWj) got accepted at TMLR with Featured Certification!

**05/2024** I am excited to announce that I will be a visiting researcher at Tampere University in the computer vision group of [Prof. Dr. Esa Rathu](https://esa.rahtu.fi/) for the next three month!

**08/2023** Our paper [On the unreasonable vulnerability of transformers for image restoration-and an easy fix](https://openaccess.thecvf.com/content/ICCV2023W/AROW/papers/Agnihotri_On_the_Unreasonable_Vulnerability_of_Transformers_for_Image_Restoration_-_ICCVW_2023_paper.pdf) got accepted to the ICCV 2023 Workshop on Adversarial Robustness In the Real World!

**09/2022** Our paper [Robust Models are less Over-Confident](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136740036.pdf) got accepted at NeurIPS 2022!

**07/2022** Our paper [FrequencyLowCut Pooling--Plug & Play against Catastrophic Overfitting](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136740036.pdf) got accepted at ECCV 2022!

**06/2022** Our paper [Aliasing and adversarial robust generalization of CNNs](https://link.springer.com/article/10.1007/s10994-022-06222-8) got accepted at ECML 2022!



Publications
======

**As large as it gets – Studying Infinitely Large Convolutions via Neural Implicit Frequency Filters**  
**J. Grabinski**, J. Keuper, M. Keuper   
TMLR 2024 (Featured Certification)     
[PDF](https://openreview.net/forum?id=xRy1YRcHWj) | [Code](https://github.com/GeJulia/NIFF)

**Improving Stability during Upsampling--on the Importance of Spatial Context**   
S. Agnihotri, **J. Grabinski**, M. Keuper   
ECCV 2024   
[PDF](https://arxiv.org/pdf/2311.17524)

**On the unreasonable vulnerability of transformers for image restoration-and an easy fix**   
S. Agnihotri, KV. Gandikota, **J. Grabinski**, P. Chandramouli, M. Keuper   
ICCV 2023, Workshop on Adversarial Robustness In the Real World   
[PDF](https://openaccess.thecvf.com/content/ICCV2023W/AROW/papers/Agnihotri_On_the_Unreasonable_Vulnerability_of_Transformers_for_Image_Restoration_-_ICCVW_2023_paper.pdf)

**Robust Models are less Over-Confident**  
**J. Grabinski**, P. Gavrikov, J. Keuper, M. Keuper    
NeurIPS 2022  
[PDF](https://openreview.net/forum?id=5K3uopkizS) | [Code](https://github.com/GeJulia/robustness_confidences_evaluation)

**FrequencyLowCut Pooling--Plug & Play against Catastrophic Overfitting**  
**J. Grabinski**, S. Jung, J. Keuper, M. Keuper    
ECCV 2022  
[PDF](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136740036.pdf) | [Code](https://github.com/GeJulia/flc_pooling)

**Aliasing and adversarial robust generalization of CNNs**  
**J. Grabinski**, J. Keuper, M. Keuper    
ECML 2022  
[PDF](https://link.springer.com/article/10.1007/s10994-022-06222-8) 

**Robust Models are less Over-Confident**  
**J. Grabinski**, P. Gavrikov, J. Keuper, M. Keuper    
ICML 2022, Workshop New Frontiers in Adversarial Machine Learning   
[PDF](https://arxiv.org/pdf/2210.05938.pdf) 

**Aliasing coincides with CNNs vulnerability towards adversarial attacks**  
**J. Grabinski**, J. Keuper, M. Keuper    
AAAI 2022, Workshop on Adversarial Machine Learning and Beyond    
[PDF](https://openreview.net/forum?id=vKc1mLxBebP) 



